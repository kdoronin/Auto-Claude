---
phase: 03-cross-validation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - apps/backend/runners/github/services/parallel_orchestrator_reviewer.py
  - apps/backend/prompts/github/pr_parallel_orchestrator.md
autonomous: true

must_haves:
  truths:
    - "Findings have a confidence score between 0.0 and 1.0"
    - "High-confidence findings (>=0.8) are included in final output"
    - "Medium-confidence findings (0.5-0.8) are framed as potential issues"
    - "Low-confidence findings (<0.5) are logged but excluded from output"
  artifacts:
    - path: "apps/backend/runners/github/services/parallel_orchestrator_reviewer.py"
      provides: "Confidence routing logic"
      contains: "_apply_confidence_routing"
    - path: "apps/backend/prompts/github/pr_parallel_orchestrator.md"
      provides: "Confidence tier documentation"
      contains: "Confidence Tiers"
  key_links:
    - from: "parallel_orchestrator_reviewer.py"
      to: "_apply_confidence_routing"
      via: "Called after finding validation"
      pattern: "_apply_confidence_routing\\(.*findings"
---

<objective>
Add confidence threshold routing to PR review findings

Purpose: Route findings through different paths based on confidence level to reduce noise from uncertain findings while preserving high-value feedback.
Output: Confidence scoring and routing logic in parallel_orchestrator_reviewer.py, updated orchestrator prompt with confidence tier documentation.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-cross-validation/03-RESEARCH.md
@apps/backend/runners/github/services/parallel_orchestrator_reviewer.py
@apps/backend/runners/github/services/pydantic_models.py
@apps/backend/prompts/github/pr_parallel_orchestrator.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add confidence routing function</name>
  <files>apps/backend/runners/github/services/parallel_orchestrator_reviewer.py</files>
  <action>
Add `_apply_confidence_routing()` function to ParallelOrchestratorReviewer class.

The function should:
1. Define ConfidenceTier as a simple class with HIGH, MEDIUM, LOW constants (0.8 and 0.5 thresholds)
2. Route each finding based on confidence:
   - HIGH (>=0.8): Keep as-is, include in output
   - MEDIUM (0.5-0.8): Prepend "[Potential] " to title, include in output
   - LOW (<0.5): Log with `logger.info()`, exclude from output
3. Return filtered list of findings with modified titles where appropriate
4. Handle missing confidence gracefully (default to 0.5)

Place the ConfidenceTier class at module level (near _validate_finding_evidence function).
Place the method in ParallelOrchestratorReviewer class after _deduplicate_findings.

Use the existing `_normalize_confidence()` method to ensure values are in 0.0-1.0 range.

Do NOT use enums - use simple string constants to match the existing codebase style.
  </action>
  <verify>
Read the modified file and verify:
- ConfidenceTier class exists with HIGH/MEDIUM/LOW constants
- `_apply_confidence_routing()` method exists in ParallelOrchestratorReviewer
- Method handles all three tiers correctly
- Logging for dropped low-confidence findings is present
  </verify>
  <done>Confidence routing function added with tier-based logic</done>
</task>

<task type="auto">
  <name>Task 2: Wire confidence routing into review pipeline</name>
  <files>apps/backend/runners/github/services/parallel_orchestrator_reviewer.py</files>
  <action>
Integrate `_apply_confidence_routing()` into the `review()` method.

In the `review()` method, after the existing evidence/scope validation loop (around line 815 where `unique_findings = validated_findings` is set):

1. Call `_apply_confidence_routing()` on validated_findings BEFORE assigning to unique_findings
2. Log the routing results: how many HIGH, MEDIUM, LOW findings

The integration point is:
```python
# After: validated_findings.append(finding)
# Add confidence routing
routed_findings = self._apply_confidence_routing(validated_findings)

# Log routing results
logger.info(
    f"[PRReview] Confidence routing: {len(routed_findings)} included, "
    f"{len(validated_findings) - len(routed_findings)} dropped (low confidence)"
)

# Use routed findings for verdict and summary
unique_findings = routed_findings
```

Make sure confidence routing happens AFTER evidence/scope validation but BEFORE verdict generation.
  </action>
  <verify>
Read the review() method and verify:
- `_apply_confidence_routing()` is called on validated_findings
- Logging of routing results is present
- Routed findings are used for verdict generation
  </verify>
  <done>Confidence routing integrated into review pipeline</done>
</task>

<task type="auto">
  <name>Task 3: Update orchestrator prompt with confidence tier guidance</name>
  <files>apps/backend/prompts/github/pr_parallel_orchestrator.md</files>
  <action>
Update the orchestrator prompt to document confidence tiers.

Add a new section after "Phase 3.5: Finding Validation" called "## Confidence Tiers":

```markdown
## Confidence Tiers

After validation, findings are routed based on confidence scores:

| Tier | Score Range | Treatment |
|------|-------------|-----------|
| HIGH | >= 0.8 | Included as reported, affects verdict |
| MEDIUM | 0.5 - 0.8 | Included with "[Potential]" prefix, affects verdict |
| LOW | < 0.5 | Logged for monitoring, excluded from output |

**Guidelines for assigning confidence:**
- 0.9+ : Direct evidence in code, multiple indicators, clear violation
- 0.8-0.9 : Strong evidence, clear pattern, high certainty
- 0.6-0.8 : Likely issue but some uncertainty, may need context
- 0.4-0.6 : Possible issue, limited evidence, context-dependent
- < 0.4 : Speculation, no direct evidence, likely false positive

**Example:**
- SQL injection with `userId` in query string: 0.95 (direct evidence)
- Missing null check where input could be null: 0.75 (likely but depends on callers)
- "This might cause issues" without specifics: 0.3 (speculation, will be dropped)
```

Also update the JSON output format example to show confidence being used for routing - no schema changes needed as confidence field already exists.
  </action>
  <verify>
Read the prompt file and verify:
- "Confidence Tiers" section exists with the table
- Guidelines for assigning confidence scores are present
- Example shows how confidence maps to inclusion decisions
  </verify>
  <done>Orchestrator prompt updated with confidence tier documentation</done>
</task>

</tasks>

<verification>
After all tasks complete:
1. Run: `apps/backend/.venv/bin/python -c "from runners.github.services.parallel_orchestrator_reviewer import ParallelOrchestratorReviewer; print('Import OK')"`
2. Verify no syntax errors in modified files
3. Grep for "_apply_confidence_routing" to confirm the method exists and is called
</verification>

<success_criteria>
- Confidence routing function exists and handles HIGH/MEDIUM/LOW tiers
- Function is wired into review pipeline after validation
- Low-confidence findings are logged but excluded from output
- Medium-confidence findings get "[Potential]" prefix
- Orchestrator prompt documents confidence tier behavior
</success_criteria>

<output>
After completion, create `.planning/phases/03-cross-validation/03-01-SUMMARY.md`
</output>
